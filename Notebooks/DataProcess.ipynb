{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing for Dentex Dataset\n",
        "\n",
        "In this notebook, we'll process the `xrays.zip` dataset and organize the data for training a deep learning model. The main tasks involved are:\n",
        "\n",
        "1. **Extracting images from a ZIP file**: We'll extract the image data from the ZIP archive and store it in a specific directory in Google Drive\n",
        "2. **Preparing the data structure**: We'll organize the images and labels in a structured format for training.\n"
      ],
      "metadata": {
        "id": "BTdEtBeaR-se"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SfNrW7jRAc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc0d904-7059-4b50-bd38-5c5dba527ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Unmount if already mounted\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "# Mount again\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r xrays/"
      ],
      "metadata": {
        "id": "GmD59MqpAj5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original'\n",
        "files = os.listdir(base_path)\n",
        "\n",
        "print(\"Files found in the folder:\")\n",
        "for f in files:\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "gHgNqDI_RHRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dde2a92-907b-4edc-ab50-4eabbb0a9f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files found in the folder:\n",
            "train_quadrant_enumeration_disease.json\n",
            "xrays.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the Images from the ZIP File\n",
        "\n",
        "We begin by extracting the X-ray images from a ZIP file stored on Google Drive. This step is necessary because the images are initially compressed in a ZIP format and need to be extracted before processing.\n",
        "\n",
        "The following code opens the ZIP file and extracts all the contents to a directory on the local machine (in this case, the `/content` directory in Google Colab).\n"
      ],
      "metadata": {
        "id": "B0QFCZqeSauc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original/xrays.zip'\n",
        "extract_path = Path('/content')\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Images extracted to: {extract_path}\")\n"
      ],
      "metadata": {
        "id": "CTgMmTp0RXMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a9156d-15a7-41d0-81f4-f24f869f73f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images extracted to: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON File\n",
        "\n",
        "In this step, we copy the JSON file `train_quadrant_enumeration_disease.json` directory in the Colab environment.\n",
        "\n",
        "This allows us to access and process the JSON file directly within the notebook. The file contains important annotations for the X-ray images that will be used in the dataset.\n"
      ],
      "metadata": {
        "id": "jEU2XeScTEAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original/train_quadrant_enumeration_disease.json' /content/"
      ],
      "metadata": {
        "id": "m4W8EShcRaLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing the Annotations and Splitting the Data\n",
        "\n",
        "In this step, we process the annotations for the X-ray images, which are stored in a JSON file. The JSON file contains details about each image, such as its ID, file name, bounding box coordinates, and the associated disease label for each bounding box.\n",
        "\n",
        "We begin by loading the JSON file and iterating through each annotation to extract the relevant information, such as the bounding box coordinates and disease IDs. This data is then used to generate YOLO-compatible labels, which are necessary for training the model.\n",
        "\n",
        "Additionally, we split the dataset into two parts:\n",
        "- 90% of the data is used for **training**.\n",
        "- 10% of the data is reserved for **validation**.\n",
        "\n",
        "The images and their corresponding labels are then organized into the following directories:\n",
        "- `train/images` and `train/labels` for the training set.\n",
        "- `val/images` and `val/labels` for the validation set.\n",
        "\n",
        "This structure ensures that the model is trained on one subset of the data and validated on another, helping evaluate its performance on unseen images.\n"
      ],
      "metadata": {
        "id": "pCs6ZrfHSl6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Paths for Colab\n",
        "json_path = \"/content/train_quadrant_enumeration_disease.json\"\n",
        "images_base_path = \"/content/xrays\"\n",
        "output_dir = \"/content/drive/MyDrive/DeepLearning/DentexDataSet/Processed/data\"\n",
        "\n",
        "# Create output directories\n",
        "splits = [\"train\", \"val\"]\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(output_dir, f\"{split}/images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, f\"{split}/labels\"), exist_ok=True)\n",
        "\n",
        "train_images_dir = os.path.join(output_dir, \"train/images\")\n",
        "train_labels_dir = os.path.join(output_dir, \"train/labels\")\n",
        "val_images_dir = os.path.join(output_dir, \"val/images\")\n",
        "val_labels_dir = os.path.join(output_dir, \"val/labels\")\n",
        "\n",
        "# Load JSON\n",
        "with open(json_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Map image ID to image metadata\n",
        "image_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "\n",
        "# Map disease ID to disease name\n",
        "categories_3 = data.get(\"categories_3\", [])\n",
        "disease_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in categories_3}\n",
        "disease_name_to_class_id = {}\n",
        "current_class_id = 0\n",
        "\n",
        "# List to store unique image names\n",
        "image_files = []\n",
        "\n",
        "# Process annotations\n",
        "for ann in data[\"annotations\"]:\n",
        "    image_id = ann[\"image_id\"]\n",
        "    bbox = ann[\"bbox\"]\n",
        "    cat3 = ann.get(\"category_id_3\")\n",
        "\n",
        "    disease_name = disease_id_to_name.get(cat3)\n",
        "    if disease_name is None:\n",
        "        continue\n",
        "\n",
        "    if disease_name not in disease_name_to_class_id:\n",
        "        disease_name_to_class_id[disease_name] = current_class_id\n",
        "        current_class_id += 1\n",
        "\n",
        "    class_id = disease_name_to_class_id[disease_name]\n",
        "\n",
        "    # Image information\n",
        "    image = image_info[image_id]\n",
        "    file_name = os.path.splitext(image[\"file_name\"])[0]\n",
        "    img_w, img_h = image[\"width\"], image[\"height\"]\n",
        "\n",
        "    # YOLO normalized coordinates\n",
        "    x_min, y_min, w, h = bbox\n",
        "    x_center = (x_min + w / 2) / img_w\n",
        "    y_center = (y_min + h / 2) / img_h\n",
        "    w /= img_w\n",
        "    h /= img_h\n",
        "\n",
        "    # Paths for source and destination\n",
        "    image_path = os.path.join(train_images_dir, f\"{file_name}.jpg\")\n",
        "    label_path = os.path.join(train_labels_dir, f\"{file_name}.txt\")\n",
        "    image_src_path = os.path.join(images_base_path, image[\"file_name\"])\n",
        "\n",
        "    if os.path.exists(image_src_path):\n",
        "        shutil.copy(image_src_path, image_path)\n",
        "    else:\n",
        "        print(f\"Image not found: {image_src_path}\")\n",
        "        continue\n",
        "\n",
        "    # Write YOLO label\n",
        "    with open(label_path, \"a\") as f:\n",
        "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "    # Save file name for later split\n",
        "    image_files.append(file_name)\n",
        "\n",
        "# Split into train/val\n",
        "random.shuffle(image_files)\n",
        "train_split = int(0.9 * len(image_files))\n",
        "val_files = image_files[train_split:]\n",
        "\n",
        "for file_name in val_files:\n",
        "    shutil.copy(os.path.join(train_images_dir, f\"{file_name}.jpg\"), val_images_dir)\n",
        "    shutil.copy(os.path.join(train_labels_dir, f\"{file_name}.txt\"), val_labels_dir)\n",
        "\n",
        "print(\"✅ YOLO conversion completed. Data organized into train and validation sets.\")\n"
      ],
      "metadata": {
        "id": "a_dqeS69RdJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccd6c41-5eef-47f1-db81-c53b512260f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ YOLO conversion completed. Data organized into train and validation sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Processed Data\n",
        "\n",
        "Once the images and annotations are processed into YOLO format, they are saved into a new folder structure: `train/images` for the images and `train/labels` for the corresponding annotation files.\n",
        "\n",
        "The processed data is saved to Google Drive for further use in model training. This structure makes it easier to manage the dataset and use it for training deep learning models such as YOLO.\n",
        "\n",
        "You can now proceed to train your model using this dataset.\n"
      ],
      "metadata": {
        "id": "yrfp0d3aS46E"
      }
    }
  ]
}