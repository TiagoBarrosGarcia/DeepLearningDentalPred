{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing for Dentex Dataset\n",
        "\n",
        "In this notebook, we'll process the `xrays.zip` dataset and organize the data for training a deep learning model. The main tasks involved are:\n",
        "\n",
        "1. **Extracting images from a ZIP file**: We'll extract the image data from the ZIP archive and store it in a specific directory in Google Drive\n",
        "2. **Preparing the data structure**: We'll organize the images and labels in a structured format for training.\n"
      ],
      "metadata": {
        "id": "BTdEtBeaR-se"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SfNrW7jRAc0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original'\n",
        "files = os.listdir(base_path)\n",
        "\n",
        "print(\"Files found in the folder:\")\n",
        "for f in files:\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "gHgNqDI_RHRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the Images from the ZIP File\n",
        "\n",
        "We begin by extracting the X-ray images from a ZIP file stored on Google Drive. This step is necessary because the images are initially compressed in a ZIP format and need to be extracted before processing.\n",
        "\n",
        "The following code opens the ZIP file and extracts all the contents to a directory on the local machine (in this case, the `/content` directory in Google Colab).\n"
      ],
      "metadata": {
        "id": "B0QFCZqeSauc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original/xrays.zip'\n",
        "extract_path = Path('/content')\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Images extracted to: {extract_path}\")\n"
      ],
      "metadata": {
        "id": "CTgMmTp0RXMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON File\n",
        "\n",
        "In this step, we copy the JSON file `train_quadrant_enumeration_disease.json` directory in the Colab environment.\n",
        "\n",
        "This allows us to access and process the JSON file directly within the notebook. The file contains important annotations for the X-ray images that will be used in the dataset.\n"
      ],
      "metadata": {
        "id": "jEU2XeScTEAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/MyDrive/DeepLearning/DentexDataSet/Original/train_quadrant_enumeration_disease.json' /content/"
      ],
      "metadata": {
        "id": "m4W8EShcRaLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing the Annotations\n",
        "\n",
        "The annotations for the X-ray images are stored in a JSON file. This file contains information about the images, such as their IDs, file names, and the bounding box coordinates for each image, as well as the disease label associated with each bounding box.\n",
        "\n",
        "We load the JSON file, iterate over each annotation, and extract the relevant information (e.g., bounding boxes and disease IDs). The annotations are then used to generate YOLO-compatible labels for training our model.\n"
      ],
      "metadata": {
        "id": "pCs6ZrfHSl6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Paths\n",
        "json_path = \"/content/train_quadrant_enumeration_disease.json\"\n",
        "images_base_path = \"/content/xrays\"\n",
        "output_dir = \"/content/drive/MyDrive/DeepLearning/DentexDataSet/Processed/data\"\n",
        "\n",
        "train_images_dir = os.path.join(output_dir, \"train/images\")\n",
        "train_labels_dir = os.path.join(output_dir, \"train/labels\")\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(train_images_dir, exist_ok=True)\n",
        "os.makedirs(train_labels_dir, exist_ok=True)\n",
        "\n",
        "# Load JSON file\n",
        "with open(json_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Auxiliary mappings\n",
        "image_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "categories_3 = data.get(\"categories_3\", [])\n",
        "disease_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in categories_3}\n",
        "disease_name_to_class_id = {}\n",
        "current_class_id = 0\n",
        "\n",
        "# Process annotations\n",
        "for ann in data[\"annotations\"]:\n",
        "    image_id = ann[\"image_id\"]\n",
        "    bbox = ann[\"bbox\"]\n",
        "    disease_id = ann.get(\"category_id_3\")\n",
        "\n",
        "    disease_name = disease_id_to_name.get(disease_id)\n",
        "    if disease_name is None:\n",
        "        continue\n",
        "\n",
        "    # Assign class_id if not already assigned\n",
        "    if disease_name not in disease_name_to_class_id:\n",
        "        disease_name_to_class_id[disease_name] = current_class_id\n",
        "        current_class_id += 1\n",
        "\n",
        "    class_id = disease_name_to_class_id[disease_name]\n",
        "    image = image_info[image_id]\n",
        "    file_name = os.path.splitext(image[\"file_name\"])[0]\n",
        "    img_w, img_h = image[\"width\"], image[\"height\"]\n",
        "\n",
        "    # YOLO bounding box format\n",
        "    x_min, y_min, w, h = bbox\n",
        "    x_center = (x_min + w / 2) / img_w\n",
        "    y_center = (y_min + h / 2) / img_h\n",
        "    w /= img_w\n",
        "    h /= img_h\n",
        "\n",
        "    # File paths\n",
        "    image_src_path = os.path.join(images_base_path, image[\"file_name\"])\n",
        "    image_dst_path = os.path.join(train_images_dir, f\"{file_name}.jpg\")\n",
        "    label_path = os.path.join(train_labels_dir, f\"{file_name}.txt\")\n",
        "\n",
        "    # Check if image exists and copy it\n",
        "    if os.path.exists(image_src_path):\n",
        "        shutil.copy(image_src_path, image_dst_path)\n",
        "\n",
        "        # Write bounding box to the .txt file in YOLO format\n",
        "        with open(label_path, \"a\") as f:\n",
        "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "    else:\n",
        "        print(f\"Image not found: {image_src_path}\")\n",
        "\n",
        "print(\"YOLO structure created successfully!\")\n"
      ],
      "metadata": {
        "id": "a_dqeS69RdJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Processed Data\n",
        "\n",
        "Once the images and annotations are processed into YOLO format, they are saved into a new folder structure: `train/images` for the images and `train/labels` for the corresponding annotation files.\n",
        "\n",
        "The processed data is saved to Google Drive for further use in model training. This structure makes it easier to manage the dataset and use it for training deep learning models such as YOLO.\n",
        "\n",
        "You can now proceed to train your model using this dataset.\n"
      ],
      "metadata": {
        "id": "yrfp0d3aS46E"
      }
    }
  ]
}